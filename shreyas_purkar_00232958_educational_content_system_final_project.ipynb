{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uveCWY_o8DVQ"
      },
      "source": [
        "# CSYE 7374: Introduction to Agentic AI - Final Project\n",
        "# Education Content System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVBGfVlJ79Ie"
      },
      "source": [
        "1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LLzaIGjvzDLz",
        "outputId": "1d7dddf7-53a4-417d-9909-5f91536408ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit<1.30.0,>=1.28.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading streamlit-1.29.0-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting openai<1.15.0,>=1.3.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 7))\n",
            "  Downloading openai-1.14.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting langchain<0.2.0,>=0.1.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-community<0.1.0,>=0.0.20 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 9))\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting faiss-cpu<1.8.0,>=1.7.4 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 12))\n",
            "  Downloading faiss_cpu-1.7.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting numpy<1.25.0,>=1.24.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 13))\n",
            "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting PyPDF2<3.1.0,>=3.0.1 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 16))\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting python-docx<1.1.0,>=0.8.11 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 17))\n",
            "  Downloading python_docx-1.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting pydantic<2.6.0,>=2.4.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 20))\n",
            "  Downloading pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyngrok<7.0.0,>=6.0.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 23))\n",
            "  Downloading pyngrok-6.1.2.tar.gz (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.8/698.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx<0.26.0,>=0.25.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 26))\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting requests<2.32.0,>=2.31.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 27))\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: python-multipart<0.1.0,>=0.0.6 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 30)) (0.0.20)\n",
            "Collecting tiktoken<0.6.0,>=0.5.1 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 31))\n",
            "  Downloading tiktoken-0.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pytest<8.0.0,>=7.4.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 34))\n",
            "  Downloading pytest-7.4.4-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (8.2.1)\n",
            "Collecting importlib-metadata<7,>=1.4 (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting packaging<24,>=16.8 (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (2.2.2)\n",
            "Collecting pillow<11,>=7.1.0 (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting protobuf<5,>=3.20 (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (18.1.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (13.9.4)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (4.14.1)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (5.3.1)\n",
            "Collecting validators<1,>=0.2 (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (6.4.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<1.15.0,>=1.3.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 7)) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<1.15.0,>=1.3.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 7)) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<1.15.0,>=1.3.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<1.15.0,>=1.3.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (2.0.42)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (3.12.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.52 (from langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx<1.1.0,>=0.8.11->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 17)) (5.4.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.6.0,>=2.4.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 20)) (0.7.0)\n",
            "Collecting pydantic-core==2.14.6 (from pydantic<2.6.0,>=2.4.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 20))\n",
            "  Downloading pydantic_core-2.14.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.26.0,>=0.25.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 26)) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.26.0,>=0.25.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 26)) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.26.0,>=0.25.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 26)) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.26.0,>=0.25.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 26)) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<2.32.0,>=2.31.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 27)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<2.32.0,>=2.31.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 27)) (2.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<0.6.0,>=0.5.1->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 31)) (2024.11.6)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<8.0.0,>=7.4.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 34)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from pytest<8.0.0,>=7.4.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 34)) (1.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (1.20.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (2.0.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (4.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<7,>=1.4->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (3.23.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.3.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.3.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.3->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (3.2.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (0.26.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading streamlit-1.29.0-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.7.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.0.1-py3-none-any.whl (237 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.4/237.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.14.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest-7.4.4-py3-none-any.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.3/325.3 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Downloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.1.2-py3-none-any.whl size=20470 sha256=7b2f0301ea296654128d478c56867645b81e828a3f9382b81b9f50ab08f26a23\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/8c/b3/17157aa83ef47aebd49e6f220ec674cce42b0dcc764e967430\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: faiss-cpu, watchdog, validators, requests, python-docx, PyPDF2, pyngrok, pydantic-core, protobuf, pillow, packaging, numpy, mypy-extensions, importlib-metadata, typing-inspect, tiktoken, pytest, pydeck, pydantic, marshmallow, httpx, openai, langsmith, dataclasses-json, langchain-core, streamlit, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.7.0\n",
            "    Uninstalling importlib_metadata-8.7.0:\n",
            "      Successfully uninstalled importlib_metadata-8.7.0\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.10.0\n",
            "    Uninstalling tiktoken-0.10.0:\n",
            "      Successfully uninstalled tiktoken-0.10.0\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 8.4.1\n",
            "    Uninstalling pytest-8.4.1:\n",
            "      Successfully uninstalled pytest-8.4.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.7\n",
            "    Uninstalling pydantic-2.11.7:\n",
            "      Successfully uninstalled pydantic-2.11.7\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.99.1\n",
            "    Uninstalling openai-1.99.1:\n",
            "      Successfully uninstalled openai-1.99.1\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.4.12\n",
            "    Uninstalling langsmith-0.4.12:\n",
            "      Successfully uninstalled langsmith-0.4.12\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.72\n",
            "    Uninstalling langchain-core-0.3.72:\n",
            "      Successfully uninstalled langchain-core-0.3.72\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.9\n",
            "    Uninstalling langchain-text-splitters-0.3.9:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.9\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "google-cloud-bigquery 3.35.1 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "jax 0.5.3 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "jaxlib 0.5.3 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "google-genai 1.28.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.25.2 which is incompatible.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.31.0 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "contourpy 1.3.3 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "albumentations 2.0.8 requires pydantic>=2.9.2, but you have pydantic 2.5.3 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "xarray 2025.7.1 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
            "scipy 1.16.1 requires numpy<2.6,>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.25.2 which is incompatible.\n",
            "pywavelets 1.9.0 requires numpy<3,>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyPDF2-3.0.1 dataclasses-json-0.6.7 faiss-cpu-1.7.4 httpx-0.25.2 importlib-metadata-6.11.0 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.53 langchain-text-splitters-0.0.2 langsmith-0.1.147 marshmallow-3.26.1 mypy-extensions-1.1.0 numpy-1.24.4 openai-1.14.3 packaging-23.2 pillow-10.4.0 protobuf-4.25.8 pydantic-2.5.3 pydantic-core-2.14.6 pydeck-0.9.1 pyngrok-6.1.2 pytest-7.4.4 python-docx-1.0.1 requests-2.31.0 streamlit-1.29.0 tiktoken-0.5.2 typing-inspect-0.9.0 validators-0.35.0 watchdog-6.0.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "25020c9e48504b258a6a11bad0d99469",
              "pip_warning": {
                "packages": [
                  "PIL",
                  "google",
                  "numpy",
                  "packaging"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Installing dependencies from requiremnts.txt in GitHub\n",
        "!pip install -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXPZvkVm8SQV"
      },
      "source": [
        "2. Education Content Agents Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import streamlit as st\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import tempfile\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Optional, Literal\n",
        "from enum import Enum\n",
        "import openai\n",
        "from pydantic import BaseModel, Field\n",
        "import faiss\n",
        "import numpy as np\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "import PyPDF2\n",
        "import docx\n",
        "import re\n",
        "import random\n",
        "\n",
        "# ======================== CONFIGURATION ========================\n",
        "class Config:\n",
        "    \"\"\"System configuration\"\"\"\n",
        "    MAX_QUIZ_QUESTIONS = 10\n",
        "    MIN_QUIZ_QUESTIONS = 3\n",
        "    DEFAULT_CHUNK_SIZE = 1000\n",
        "    DEFAULT_CHUNK_OVERLAP = 200\n",
        "    COST_PER_CALL_GPT35 = 0.002\n",
        "    COST_PER_CALL_GPT4 = 0.01\n",
        "\n",
        "# ======================== LLM MANAGEMENT ========================\n",
        "class LLMInterface:\n",
        "    \"\"\"Centralized LLM management - tracks every call for cost analysis\"\"\"\n",
        "    \n",
        "    def __init__(self, api_key: str, model: str = \"gpt-3.5-turbo\"):\n",
        "        self.client = openai.OpenAI(api_key=api_key.strip())\n",
        "        self.model = model\n",
        "        self.call_count = 0\n",
        "        self.total_cost = 0.0\n",
        "        \n",
        "    def make_call(self, messages: List[Dict], response_format=None, temperature=0.3):\n",
        "        \"\"\"Single point for ALL LLM calls - easy to monitor/debug\"\"\"\n",
        "        self.call_count += 1\n",
        "        cost = Config.COST_PER_CALL_GPT35 if \"gpt-3.5\" in self.model else Config.COST_PER_CALL_GPT4\n",
        "        self.total_cost += cost\n",
        "        \n",
        "        try:\n",
        "            request_params = {\n",
        "                \"model\": self.model,\n",
        "                \"messages\": messages,\n",
        "                \"temperature\": temperature,\n",
        "                \"max_tokens\": 2000\n",
        "            }\n",
        "            \n",
        "            if response_format and isinstance(response_format, dict):\n",
        "                request_params[\"response_format\"] = response_format\n",
        "            \n",
        "            response = self.client.chat.completions.create(**request_params)\n",
        "            return response.choices[0].message\n",
        "            \n",
        "        except Exception as e:\n",
        "            return type('obj', (object,), {'content': f\"Error: {str(e)}\"})\n",
        "            \n",
        "    def get_metrics(self) -> Dict:\n",
        "        \"\"\"Return usage metrics\"\"\"\n",
        "        return {\n",
        "            \"total_calls\": self.call_count,\n",
        "            \"total_cost\": round(self.total_cost, 4),\n",
        "            \"average_cost_per_call\": round(self.total_cost / max(1, self.call_count), 4)\n",
        "        }\n",
        "\n",
        "# ======================== DATA MODELS ========================\n",
        "class QuestionDifficulty(str, Enum):\n",
        "    EASY = \"easy\"\n",
        "    MEDIUM = \"medium\"\n",
        "    HARD = \"hard\"\n",
        "\n",
        "class QuizQuestion(BaseModel):\n",
        "    question: str = Field(description=\"The quiz question\")\n",
        "    options: List[str] = Field(description=\"Four multiple choice options\", min_length=4, max_length=4)\n",
        "    correct_answer: int = Field(description=\"Index of correct answer (0-3)\", ge=0, le=3)\n",
        "    explanation: str = Field(description=\"Brief explanation of the correct answer\")\n",
        "    difficulty: QuestionDifficulty = Field(default=QuestionDifficulty.MEDIUM)\n",
        "\n",
        "class QuizContent(BaseModel):\n",
        "    questions: List[QuizQuestion] = Field(description=\"List of quiz questions\")\n",
        "    topic: str = Field(description=\"Main topic of the quiz\")\n",
        "    total_questions: int = Field(description=\"Number of questions\")\n",
        "\n",
        "# ======================== AGENTS ========================\n",
        "\n",
        "class DocumentProcessorAgent:\n",
        "    \"\"\" Agent 1: Document Processor: Accepts document with .pdf, .txt and .docx extention. Creates chunks of document content using langchain. \"\"\"\n",
        "    def __init__(self):\n",
        "        self.name = \"DocumentProcessor\"\n",
        "        self.uses_llm = False\n",
        "        \n",
        "    def extract_text_from_file(self, file_path: str, file_type: str) -> str:\n",
        "        try:\n",
        "            if file_type == \"pdf\":\n",
        "                return self._extract_from_pdf(file_path)\n",
        "            elif file_type == \"docx\":\n",
        "                return self._extract_from_docx(file_path)\n",
        "            elif file_type == \"txt\":\n",
        "                return self._extract_from_txt(file_path)\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported file type: {file_type}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Document processing failed: {e}\")\n",
        "            return \"\"\n",
        "            \n",
        "    def _extract_from_pdf(self, file_path: str) -> str:\n",
        "        text = \"\"\n",
        "        try:\n",
        "            with open(file_path, 'rb') as file:\n",
        "                pdf_reader = PyPDF2.PdfReader(file)\n",
        "                for page in pdf_reader.pages:\n",
        "                    text += page.extract_text() + \"\\n\"\n",
        "        except Exception as e:\n",
        "            print(f\"PDF extraction failed: {e}\")\n",
        "        return text\n",
        "        \n",
        "    def _extract_from_docx(self, file_path: str) -> str:\n",
        "        try:\n",
        "            doc = docx.Document(file_path)\n",
        "            text = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            print(f\"DOCX extraction failed: {e}\")\n",
        "            return \"\"\n",
        "            \n",
        "    def _extract_from_txt(self, file_path: str) -> str:\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                return file.read()\n",
        "        except Exception as e:\n",
        "            print(f\"TXT extraction failed: {e}\")\n",
        "            return \"\"\n",
        "            \n",
        "    def chunk_text(self, text: str) -> List[str]:\n",
        "        if not text.strip():\n",
        "            return []\n",
        "            \n",
        "        splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=Config.DEFAULT_CHUNK_SIZE,\n",
        "            chunk_overlap=Config.DEFAULT_CHUNK_OVERLAP,\n",
        "            length_function=len\n",
        "        )\n",
        "        return splitter.split_text(text)  \n",
        "\n",
        "class VectorStore:\n",
        "    \"\"\" Utility to create emdeddings for chunks and to store them in FAISS \"\"\"\n",
        "    def __init__(self, api_key: str):\n",
        "        self.name = \"VectorStore\"\n",
        "        self.uses_llm = False\n",
        "        \n",
        "        try:\n",
        "            self.embeddings = OpenAIEmbeddings(\n",
        "                openai_api_key=api_key,\n",
        "                model=\"text-embedding-ada-002\"\n",
        "            )\n",
        "            self.vector_store = None\n",
        "        except Exception as e:\n",
        "            self.embeddings = None\n",
        "        \n",
        "    def create_vector_store(self, text_chunks: List[str]) -> bool:\n",
        "        if not text_chunks or not self.embeddings:\n",
        "            return False\n",
        "            \n",
        "        try:\n",
        "            self.vector_store = FAISS.from_texts(\n",
        "                texts=text_chunks,\n",
        "                embedding=self.embeddings\n",
        "            )\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            return False\n",
        "            \n",
        "    def retrieve_relevant_content(self, query: str, k: int = 5) -> List[str]:\n",
        "        if not self.vector_store:\n",
        "            return []\n",
        "            \n",
        "        try:\n",
        "            docs = self.vector_store.similarity_search(query, k=k)\n",
        "            return [doc.page_content for doc in docs]\n",
        "        except Exception as e:\n",
        "            return []\n",
        "\n",
        "            "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
