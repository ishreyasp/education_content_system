{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uveCWY_o8DVQ"
      },
      "source": [
        "# CSYE 7374: Introduction to Agentic AI - Final Project\n",
        "# Education Content System"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVBGfVlJ79Ie"
      },
      "source": [
        "1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LLzaIGjvzDLz",
        "outputId": "1d7dddf7-53a4-417d-9909-5f91536408ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit<1.30.0,>=1.28.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading streamlit-1.29.0-py2.py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting openai<1.15.0,>=1.3.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 7))\n",
            "  Downloading openai-1.14.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting langchain<0.2.0,>=0.1.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-community<0.1.0,>=0.0.20 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 9))\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting faiss-cpu<1.8.0,>=1.7.4 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 12))\n",
            "  Downloading faiss_cpu-1.7.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting numpy<1.25.0,>=1.24.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 13))\n",
            "  Downloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting PyPDF2<3.1.0,>=3.0.1 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 16))\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting python-docx<1.1.0,>=0.8.11 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 17))\n",
            "  Downloading python_docx-1.0.1-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting pydantic<2.6.0,>=2.4.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 20))\n",
            "  Downloading pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyngrok<7.0.0,>=6.0.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 23))\n",
            "  Downloading pyngrok-6.1.2.tar.gz (698 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.8/698.8 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx<0.26.0,>=0.25.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 26))\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting requests<2.32.0,>=2.31.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 27))\n",
            "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: python-multipart<0.1.0,>=0.0.6 in /usr/local/lib/python3.11/dist-packages (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 30)) (0.0.20)\n",
            "Collecting tiktoken<0.6.0,>=0.5.1 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 31))\n",
            "  Downloading tiktoken-0.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting pytest<8.0.0,>=7.4.0 (from -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 34))\n",
            "  Downloading pytest-7.4.4-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (8.2.1)\n",
            "Collecting importlib-metadata<7,>=1.4 (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting packaging<24,>=16.8 (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (2.2.2)\n",
            "Collecting pillow<11,>=7.1.0 (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting protobuf<5,>=3.20 (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (18.1.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (2.9.0.post0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (13.9.4)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (4.14.1)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (5.3.1)\n",
            "Collecting validators<1,>=0.2 (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (6.4.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4))\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<1.15.0,>=1.3.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 7)) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<1.15.0,>=1.3.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 7)) (1.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<1.15.0,>=1.3.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 7)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<1.15.0,>=1.3.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (2.0.42)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (3.12.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.52 (from langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx<1.1.0,>=0.8.11->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 17)) (5.4.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.6.0,>=2.4.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 20)) (0.7.0)\n",
            "Collecting pydantic-core==2.14.6 (from pydantic<2.6.0,>=2.4.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 20))\n",
            "  Downloading pydantic_core-2.14.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.26.0,>=0.25.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 26)) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.26.0,>=0.25.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 26)) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.26.0,>=0.25.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 26)) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.26.0,>=0.25.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 26)) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<2.32.0,>=2.31.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 27)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<2.32.0,>=2.31.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 27)) (2.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<0.6.0,>=0.5.1->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 31)) (2024.11.6)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest<8.0.0,>=7.4.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 34)) (2.1.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from pytest<8.0.0,>=7.4.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 34)) (1.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (1.20.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (4.25.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (2.0.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (4.0.12)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<7,>=1.4->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (3.23.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (1.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.3.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.3.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3,>=2.7.3->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (2.19.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (3.2.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (3.0.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (0.26.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit<1.30.0,>=1.28.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 4)) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.0->-r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt (line 8))\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading streamlit-1.29.0-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.14.3-py3-none-any.whl (262 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.1.20-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.7.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.0.1-py3-none-any.whl (237 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.4/237.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.14.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest-7.4.4-py3-none-any.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.3/325.3 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Downloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.0.2-py3-none-any.whl (23 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-6.1.2-py3-none-any.whl size=20470 sha256=7b2f0301ea296654128d478c56867645b81e828a3f9382b81b9f50ab08f26a23\n",
            "  Stored in directory: /root/.cache/pip/wheels/8f/8c/b3/17157aa83ef47aebd49e6f220ec674cce42b0dcc764e967430\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: faiss-cpu, watchdog, validators, requests, python-docx, PyPDF2, pyngrok, pydantic-core, protobuf, pillow, packaging, numpy, mypy-extensions, importlib-metadata, typing-inspect, tiktoken, pytest, pydeck, pydantic, marshmallow, httpx, openai, langsmith, dataclasses-json, langchain-core, streamlit, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.33.2\n",
            "    Uninstalling pydantic_core-2.33.2:\n",
            "      Successfully uninstalled pydantic_core-2.33.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.3.0\n",
            "    Uninstalling pillow-11.3.0:\n",
            "      Successfully uninstalled pillow-11.3.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.7.0\n",
            "    Uninstalling importlib_metadata-8.7.0:\n",
            "      Successfully uninstalled importlib_metadata-8.7.0\n",
            "  Attempting uninstall: tiktoken\n",
            "    Found existing installation: tiktoken 0.10.0\n",
            "    Uninstalling tiktoken-0.10.0:\n",
            "      Successfully uninstalled tiktoken-0.10.0\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 8.4.1\n",
            "    Uninstalling pytest-8.4.1:\n",
            "      Successfully uninstalled pytest-8.4.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.11.7\n",
            "    Uninstalling pydantic-2.11.7:\n",
            "      Successfully uninstalled pydantic-2.11.7\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.99.1\n",
            "    Uninstalling openai-1.99.1:\n",
            "      Successfully uninstalled openai-1.99.1\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.4.12\n",
            "    Uninstalling langsmith-0.4.12:\n",
            "      Successfully uninstalled langsmith-0.4.12\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.72\n",
            "    Uninstalling langchain-core-0.3.72:\n",
            "      Successfully uninstalled langchain-core-0.3.72\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.9\n",
            "    Uninstalling langchain-text-splitters-0.3.9:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.9\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.27\n",
            "    Uninstalling langchain-0.3.27:\n",
            "      Successfully uninstalled langchain-0.3.27\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.31.0 which is incompatible.\n",
            "xarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "google-cloud-bigquery 3.35.1 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "blosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "jax 0.5.3 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "jaxlib 0.5.3 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "google-genai 1.28.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.25.2 which is incompatible.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.31.0 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "contourpy 1.3.3 requires numpy>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "albumentations 2.0.8 requires pydantic>=2.9.2, but you have pydantic 2.5.3 which is incompatible.\n",
            "xarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.24.4 which is incompatible.\n",
            "xarray 2025.7.1 requires packaging>=24.1, but you have packaging 23.2 which is incompatible.\n",
            "scipy 1.16.1 requires numpy<2.6,>=1.25.2, but you have numpy 1.24.4 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
            "arviz 0.22.0 requires numpy>=1.26.0, but you have numpy 1.24.4 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.25.2 which is incompatible.\n",
            "pywavelets 1.9.0 requires numpy<3,>=1.25, but you have numpy 1.24.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.4 which is incompatible.\n",
            "pymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.24.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyPDF2-3.0.1 dataclasses-json-0.6.7 faiss-cpu-1.7.4 httpx-0.25.2 importlib-metadata-6.11.0 langchain-0.1.20 langchain-community-0.0.38 langchain-core-0.1.53 langchain-text-splitters-0.0.2 langsmith-0.1.147 marshmallow-3.26.1 mypy-extensions-1.1.0 numpy-1.24.4 openai-1.14.3 packaging-23.2 pillow-10.4.0 protobuf-4.25.8 pydantic-2.5.3 pydantic-core-2.14.6 pydeck-0.9.1 pyngrok-6.1.2 pytest-7.4.4 python-docx-1.0.1 requests-2.31.0 streamlit-1.29.0 tiktoken-0.5.2 typing-inspect-0.9.0 validators-0.35.0 watchdog-6.0.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "25020c9e48504b258a6a11bad0d99469",
              "pip_warning": {
                "packages": [
                  "PIL",
                  "google",
                  "numpy",
                  "packaging"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Installing dependencies from requiremnts.txt in GitHub\n",
        "!pip install -r https://raw.githubusercontent.com/ishreyasp/education_content_system/refs/heads/main/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXPZvkVm8SQV"
      },
      "source": [
        "2. Education Content Agents Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile education_system.py\n",
        "\n",
        "#Imports\n",
        "import streamlit as st\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import tempfile\n",
        "from datetime import datetime\n",
        "from typing import List, Dict, Optional, Literal\n",
        "from enum import Enum\n",
        "import openai\n",
        "from pydantic import BaseModel, Field\n",
        "import faiss\n",
        "import numpy as np\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "import PyPDF2\n",
        "import docx\n",
        "import re\n",
        "import random\n",
        "import hashlib\n",
        "import sqlite3\n",
        "from pathlib import Path\n",
        "\n",
        "# ======================== CONFIGURATION ========================\n",
        "class Config:\n",
        "    \"\"\"System configuration\"\"\"\n",
        "    MAX_QUIZ_QUESTIONS = 10\n",
        "    MIN_QUIZ_QUESTIONS = 3\n",
        "    DEFAULT_CHUNK_SIZE = 1000\n",
        "    DEFAULT_CHUNK_OVERLAP = 200\n",
        "    COST_PER_CALL_GPT35 = 0.002\n",
        "    COST_PER_CALL_GPT4 = 0.01\n",
        "    DATABASE_PATH = \"quiz_system.db\"\n",
        "\n",
        "# ======================== USER ROLES ========================\n",
        "class UserRole(str, Enum):\n",
        "    PROFESSOR = \"professor\"\n",
        "    STUDENT = \"student\"\n",
        "\n",
        "# ======================== AUTHENTICATION SYSTEM ========================\n",
        "class AuthenticationManager:\n",
        "    \"\"\"Handle user authentication and session management\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.db_path = Config.DATABASE_PATH\n",
        "        self.init_database()\n",
        "        self.create_default_users()\n",
        "    \n",
        "    def init_database(self):\n",
        "        \"\"\"Initialize the database with user tables\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        \n",
        "        # Create users table\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS users (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                username TEXT UNIQUE NOT NULL,\n",
        "                password_hash TEXT NOT NULL,\n",
        "                role TEXT NOT NULL,\n",
        "                full_name TEXT NOT NULL,\n",
        "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "            )\n",
        "        ''')\n",
        "        \n",
        "        # Create quiz sessions table for cross-browser support\n",
        "        cursor.execute('''\n",
        "            CREATE TABLE IF NOT EXISTS quiz_sessions (\n",
        "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "                session_id TEXT UNIQUE NOT NULL,\n",
        "                quiz_data TEXT NOT NULL,\n",
        "                created_by TEXT NOT NULL,\n",
        "                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
        "                expires_at TIMESTAMP NOT NULL\n",
        "            )\n",
        "        ''')\n",
        "        \n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "    \n",
        "    def create_default_users(self):\n",
        "        \"\"\"Create default users for demonstration\"\"\"\n",
        "        default_users = [\n",
        "            (\"prof_smith\", \"password123\", \"professor\", \"Professor Smith\"),\n",
        "            (\"prof_jones\", \"password123\", \"professor\", \"Professor Jones\"),\n",
        "            (\"student_alice\", \"password123\", \"student\", \"Alice Johnson\"),\n",
        "            (\"student_bob\", \"password123\", \"student\", \"Bob Wilson\"),\n",
        "            (\"student_charlie\", \"password123\", \"student\", \"Charlie Brown\")\n",
        "        ]\n",
        "        \n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        \n",
        "        for username, password, role, full_name in default_users:\n",
        "            try:\n",
        "                password_hash = self.hash_password(password)\n",
        "                cursor.execute('''\n",
        "                    INSERT OR IGNORE INTO users (username, password_hash, role, full_name)\n",
        "                    VALUES (?, ?, ?, ?)\n",
        "                ''', (username, password_hash, role, full_name))\n",
        "            except:\n",
        "                pass  # User already exists\n",
        "        \n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "    \n",
        "    def hash_password(self, password: str) -> str:\n",
        "        \"\"\"Hash password using SHA-256\"\"\"\n",
        "        return hashlib.sha256(password.encode()).hexdigest()\n",
        "    \n",
        "    def authenticate_user(self, username: str, password: str) -> Optional[Dict]:\n",
        "        \"\"\"Authenticate user and return user info if successful\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        \n",
        "        password_hash = self.hash_password(password)\n",
        "        cursor.execute('''\n",
        "            SELECT username, role, full_name FROM users \n",
        "            WHERE username = ? AND password_hash = ?\n",
        "        ''', (username, password_hash))\n",
        "        \n",
        "        result = cursor.fetchone()\n",
        "        conn.close()\n",
        "        \n",
        "        if result:\n",
        "            return {\n",
        "                \"username\": result[0],\n",
        "                \"role\": result[1],\n",
        "                \"full_name\": result[2]\n",
        "            }\n",
        "        return None\n",
        "    \n",
        "    def get_all_users(self) -> List[Dict]:\n",
        "        \"\"\"Get all users for admin purposes\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        \n",
        "        cursor.execute('SELECT username, role, full_name, created_at FROM users ORDER BY role, username')\n",
        "        results = cursor.fetchall()\n",
        "        conn.close()\n",
        "        \n",
        "        return [{\"username\": r[0], \"role\": r[1], \"full_name\": r[2], \"created_at\": r[3]} for r in results]\n",
        "    \n",
        "    def store_quiz_session(self, quiz_data: Dict, created_by: str) -> str:\n",
        "        \"\"\"Store quiz data for cross-browser access\"\"\"\n",
        "        import uuid\n",
        "        from datetime import datetime, timedelta\n",
        "        \n",
        "        session_id = str(uuid.uuid4())\n",
        "        expires_at = datetime.now() + timedelta(hours=24)  \n",
        "        \n",
        "        # Convert QuizContent object to JSON-serializable format\n",
        "        if 'quiz' in quiz_data and hasattr(quiz_data['quiz'], 'model_dump'):\n",
        "            # Convert Pydantic model to dictionary\n",
        "            serializable_quiz_data = quiz_data.copy()\n",
        "            serializable_quiz_data['quiz'] = quiz_data['quiz'].model_dump()\n",
        "            \n",
        "            # Convert datetime objects to ISO format strings\n",
        "            if 'created_at' in serializable_quiz_data['quiz']:\n",
        "                created_at = serializable_quiz_data['quiz']['created_at']\n",
        "                if hasattr(created_at, 'isoformat'):\n",
        "                    serializable_quiz_data['quiz']['created_at'] = created_at.isoformat()\n",
        "        else:\n",
        "            serializable_quiz_data = quiz_data\n",
        "        \n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        \n",
        "        cursor.execute('''\n",
        "            INSERT INTO quiz_sessions (session_id, quiz_data, created_by, expires_at)\n",
        "            VALUES (?, ?, ?, ?)\n",
        "        ''', (session_id, json.dumps(serializable_quiz_data), created_by, expires_at))\n",
        "        \n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "        \n",
        "        return session_id\n",
        "    \n",
        "    def get_quiz_session(self, session_id: str) -> Optional[Dict]:\n",
        "        \"\"\"Retrieve quiz data by session ID\"\"\"\n",
        "        conn = sqlite3.connect(self.db_path)\n",
        "        cursor = conn.cursor()\n",
        "        \n",
        "        cursor.execute('''\n",
        "            SELECT quiz_data, created_by FROM quiz_sessions \n",
        "            WHERE session_id = ? AND expires_at > datetime('now')\n",
        "        ''', (session_id,))\n",
        "        \n",
        "        result = cursor.fetchone()\n",
        "        conn.close()\n",
        "        \n",
        "        if result:\n",
        "            quiz_data = json.loads(result[0])\n",
        "            \n",
        "            # Convert datetime string back to datetime object if needed\n",
        "            if 'quiz' in quiz_data and 'created_at' in quiz_data['quiz']:\n",
        "                created_at_str = quiz_data['quiz']['created_at']\n",
        "                if isinstance(created_at_str, str):\n",
        "                    try:\n",
        "                        from datetime import datetime\n",
        "                        quiz_data['quiz']['created_at'] = datetime.fromisoformat(created_at_str.replace('Z', '+00:00'))\n",
        "                    except:\n",
        "                        quiz_data['quiz']['created_at'] = datetime.now()\n",
        "            \n",
        "            return {\n",
        "                \"quiz_data\": quiz_data,\n",
        "                \"created_by\": result[1]\n",
        "            }\n",
        "        return None\n",
        "\n",
        "# ======================== LLM MANAGEMENT ========================\n",
        "class LLMInterface:\n",
        "    \"\"\"Centralized LLM management - tracks every call for cost analysis\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: str, model: str = \"gpt-3.5-turbo\"):\n",
        "        self.client = openai.OpenAI(api_key=api_key.strip())\n",
        "        self.model = model\n",
        "        self.call_count = 0\n",
        "        self.total_cost = 0.0\n",
        "\n",
        "    def make_call(self, messages: List[Dict], response_format=None, temperature=0.3, max_retries=3):\n",
        "        \"\"\"Single point for ALL LLM calls with proper error handling and retries\"\"\"\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                self.call_count += 1\n",
        "                cost = Config.COST_PER_CALL_GPT35 if \"gpt-3.5\" in self.model else Config.COST_PER_CALL_GPT4\n",
        "                self.total_cost += cost\n",
        "\n",
        "                request_params = {\n",
        "                    \"model\": self.model,\n",
        "                    \"messages\": messages,\n",
        "                    \"temperature\": temperature,\n",
        "                    \"max_tokens\": 2000\n",
        "                }\n",
        "\n",
        "                if response_format and isinstance(response_format, dict):\n",
        "                    request_params[\"response_format\"] = response_format\n",
        "\n",
        "                response = self.client.chat.completions.create(**request_params)\n",
        "                return {\"success\": True, \"content\": response.choices[0].message.content}\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt == max_retries - 1:  # Last attempt\n",
        "                    return {\"success\": False, \"error\": str(e)}\n",
        "                time.sleep(2 ** attempt)  # Exponential backoff\n",
        "        \n",
        "        return {\"success\": False, \"error\": \"Max retries exceeded\"}\n",
        "\n",
        "    def get_metrics(self) -> Dict:\n",
        "        \"\"\"Return usage metrics\"\"\"\n",
        "        return {\n",
        "            \"total_calls\": self.call_count,\n",
        "            \"total_cost\": round(self.total_cost, 4),\n",
        "            \"average_cost_per_call\": round(self.total_cost / max(1, self.call_count), 4)\n",
        "        }\n",
        "\n",
        "# ======================== DATA MODELS ========================\n",
        "class QuestionDifficulty(str, Enum):\n",
        "    EASY = \"easy\"\n",
        "    MEDIUM = \"medium\"\n",
        "    HARD = \"hard\"\n",
        "\n",
        "class QuizQuestion(BaseModel):\n",
        "    question: str = Field(description=\"The quiz question\")\n",
        "    options: List[str] = Field(description=\"Four multiple choice options\", min_length=4, max_length=4)\n",
        "    correct_answer: int = Field(description=\"Index of correct answer (0-3)\", ge=0, le=3)\n",
        "    explanation: str = Field(description=\"Brief explanation of the correct answer\")\n",
        "    difficulty: QuestionDifficulty = Field(default=QuestionDifficulty.MEDIUM)\n",
        "\n",
        "class QuizContent(BaseModel):\n",
        "    questions: List[QuizQuestion] = Field(description=\"List of quiz questions\")\n",
        "    topic: str = Field(description=\"Main topic of the quiz\")\n",
        "    total_questions: int = Field(description=\"Number of questions\")\n",
        "    difficulty_level: QuestionDifficulty = Field(description=\"Overall quiz difficulty set by professor\")\n",
        "    created_by: str = Field(description=\"Professor who created the quiz\")\n",
        "    created_at: datetime = Field(description=\"When the quiz was created\")\n",
        "\n",
        "# ======================== AGENTS (Same as before) ========================\n",
        "\n",
        "class DocumentProcessorAgent:\n",
        "    \"\"\" Agent 1: Document Processor: Accepts document with .pdf, .txt and .docx extention. Creates chunks of document content using langchain. \"\"\"\n",
        "    def __init__(self):\n",
        "        self.name = \"DocumentProcessor\"\n",
        "        self.uses_llm = False\n",
        "\n",
        "    def extract_text_from_file(self, file_path: str, file_type: str) -> Dict:\n",
        "        try:\n",
        "            if file_type == \"pdf\":\n",
        "                text = self._extract_from_pdf(file_path)\n",
        "            elif file_type == \"docx\":\n",
        "                text = self._extract_from_docx(file_path)\n",
        "            elif file_type == \"txt\":\n",
        "                text = self._extract_from_txt(file_path)\n",
        "            else:\n",
        "                return {\"success\": False, \"error\": f\"Unsupported file type: {file_type}\"}\n",
        "            \n",
        "            if not text.strip():\n",
        "                return {\"success\": False, \"error\": \"No content extracted from document\"}\n",
        "            \n",
        "            return {\"success\": True, \"text\": text}\n",
        "            \n",
        "        except Exception as e:\n",
        "            return {\"success\": False, \"error\": f\"Document processing failed: {str(e)}\"}\n",
        "\n",
        "    def validate_content_quality(self, text: str) -> Dict:\n",
        "        \"\"\"Validate if document has enough content for educational quiz generation\"\"\"\n",
        "        if not text or not text.strip():\n",
        "            return {\n",
        "                \"is_valid\": False,\n",
        "                \"error\": \"No content found in document\",\n",
        "                \"suggestion\": \"Please upload a document with actual text content.\"\n",
        "            }\n",
        "\n",
        "        # Count sentences using multiple sentence endings\n",
        "        import re\n",
        "        cleaned_text = text.strip()\n",
        "        sentence_pattern = r'[.!?]+[\\s\\n]+|[.!?]+$'\n",
        "        sentences = re.split(sentence_pattern, cleaned_text)\n",
        "        meaningful_sentences = [s.strip() for s in sentences if s.strip() and len(s.strip()) > 10]\n",
        "        sentence_count = len(meaningful_sentences)\n",
        "\n",
        "        # Count words for additional validation\n",
        "        words = cleaned_text.split()\n",
        "        word_count = len(words)\n",
        "\n",
        "        # Stricter validation criteria\n",
        "        if sentence_count < 5:\n",
        "            return {\n",
        "                \"is_valid\": False,\n",
        "                \"error\": f\"Document contains {sentence_count} meaningful sentence(s)\",\n",
        "                \"suggestion\": \"Educational content should have at least 5 sentences to generate a proper quiz. Please upload a more comprehensive document.\"\n",
        "            }\n",
        "\n",
        "        if word_count < 100:\n",
        "            return {\n",
        "                \"is_valid\": False,\n",
        "                \"error\": f\"Document contains only {word_count} words\",\n",
        "                \"suggestion\": \"Educational content should have at least 100 words to generate meaningful quiz questions. Please upload a longer document.\"\n",
        "            }\n",
        "\n",
        "        return {\n",
        "            \"is_valid\": True,\n",
        "            \"sentence_count\": sentence_count,\n",
        "            \"word_count\": word_count,\n",
        "            \"message\": f\"Document validated: {sentence_count} sentences, {word_count} words\"\n",
        "        }\n",
        "\n",
        "    def _extract_from_pdf(self, file_path: str) -> str:\n",
        "        text = \"\"\n",
        "        try:\n",
        "            with open(file_path, 'rb') as file:\n",
        "                pdf_reader = PyPDF2.PdfReader(file)\n",
        "                for page in pdf_reader.pages:\n",
        "                    text += page.extract_text() + \"\\n\"\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"PDF extraction failed: {e}\")\n",
        "        return text\n",
        "\n",
        "    def _extract_from_docx(self, file_path: str) -> str:\n",
        "        try:\n",
        "            doc = docx.Document(file_path)\n",
        "            text = \"\\n\".join([paragraph.text for paragraph in doc.paragraphs])\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"DOCX extraction failed: {e}\")\n",
        "\n",
        "    def _extract_from_txt(self, file_path: str) -> str:\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                return file.read()\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"TXT extraction failed: {e}\")\n",
        "\n",
        "    def chunk_text(self, text: str) -> List[str]:\n",
        "        if not text.strip():\n",
        "            return []\n",
        "\n",
        "        splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=Config.DEFAULT_CHUNK_SIZE,\n",
        "            chunk_overlap=Config.DEFAULT_CHUNK_OVERLAP,\n",
        "            length_function=len\n",
        "        )\n",
        "        return splitter.split_text(text)\n",
        "\n",
        "class VectorStore:\n",
        "    \"\"\" Utility to create emdeddings for chunks and to store them in FAISS \"\"\"\n",
        "    def __init__(self, api_key: str):\n",
        "        self.name = \"VectorStore\"\n",
        "        self.uses_llm = False\n",
        "\n",
        "        try:\n",
        "            self.embeddings = OpenAIEmbeddings(\n",
        "                openai_api_key=api_key,\n",
        "                model=\"text-embedding-ada-002\"\n",
        "            )\n",
        "            self.vector_store = None\n",
        "        except Exception as e:\n",
        "            self.embeddings = None\n",
        "\n",
        "    def create_vector_store(self, text_chunks: List[str]) -> Dict:\n",
        "        if not text_chunks:\n",
        "            return {\"success\": False, \"error\": \"No text chunks provided\"}\n",
        "        \n",
        "        if not self.embeddings:\n",
        "            return {\"success\": False, \"error\": \"Embeddings not initialized\"}\n",
        "\n",
        "        try:\n",
        "            self.vector_store = FAISS.from_texts(\n",
        "                texts=text_chunks,\n",
        "                embedding=self.embeddings\n",
        "            )\n",
        "            return {\"success\": True, \"message\": f\"Vector store created with {len(text_chunks)} chunks\"}\n",
        "        except Exception as e:\n",
        "            return {\"success\": False, \"error\": f\"Vector store creation failed: {str(e)}\"}\n",
        "\n",
        "    def retrieve_relevant_content(self, query: str, k: int = 5) -> List[str]:\n",
        "        if not self.vector_store:\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            docs = self.vector_store.similarity_search(query, k=k)\n",
        "            return [doc.page_content for doc in docs]\n",
        "        except Exception as e:\n",
        "            return []\n",
        "\n",
        "class ContentAnalyzerAgent:\n",
        "    \"\"\" Agent 2: Content Analyzer: Sends chunks of content to LLM to get the details of the content like topic, key concepts and difficulty level. \"\"\"\n",
        "\n",
        "    def __init__(self, llm_interface: LLMInterface):\n",
        "        self.name = \"ContentAnalyzer\"\n",
        "        self.uses_llm = True\n",
        "        self.llm = llm_interface\n",
        "\n",
        "    def analyze_content_for_quiz(self, content_chunks: List[str]) -> Dict:\n",
        "        if not content_chunks:\n",
        "            return {\"success\": False, \"error\": \"No content chunks provided for analysis\"}\n",
        "\n",
        "        combined_content = \"\\n\".join(content_chunks[:3])\n",
        "\n",
        "        messages = [{\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"\"\"Analyze the educational content and identify:\n",
        "            1. Main topic/subject\n",
        "            2. Key concepts that could be tested\n",
        "            3. Content complexity level\n",
        "\n",
        "            Respond in JSON format with keys: topic, key_concepts (array), complexity (easy/medium/hard).\"\"\"\n",
        "        }, {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Analyze this educational content:\\n\\n{combined_content[:2000]}\"\n",
        "        }]\n",
        "\n",
        "        response = self.llm.make_call(messages, {\"type\": \"json_object\"})\n",
        "        \n",
        "        if not response[\"success\"]:\n",
        "            return {\"success\": False, \"error\": f\"LLM analysis failed: {response['error']}\"}\n",
        "\n",
        "        try:\n",
        "            analysis = json.loads(response[\"content\"])\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"topic\": analysis.get(\"topic\", \"Educational Content\"),\n",
        "                \"key_concepts\": analysis.get(\"key_concepts\", []),\n",
        "                \"complexity\": analysis.get(\"complexity\", \"medium\")\n",
        "            }\n",
        "        except json.JSONDecodeError as e:\n",
        "            return {\"success\": False, \"error\": f\"Failed to parse analysis JSON: {str(e)}\"}\n",
        "\n",
        "class QuizGeneratorAgent:\n",
        "    \"\"\" Agent 3: Quiz Generator: Creates multiple choice questions for given content. \"\"\"\n",
        "\n",
        "    def __init__(self, llm_interface: LLMInterface):\n",
        "        self.name = \"QuizGenerator\"\n",
        "        self.uses_llm = True\n",
        "        self.llm = llm_interface\n",
        "\n",
        "    def generate_quiz(self, content_chunks: List[str], analysis: Dict, num_questions: int = 5, \n",
        "                     difficulty_level: str = \"medium\", professor_name: str = \"Professor\") -> Dict:\n",
        "        if not content_chunks:\n",
        "            return {\"success\": False, \"error\": \"No content chunks provided for quiz generation\"}\n",
        "\n",
        "        if not analysis.get(\"success\", False):\n",
        "            return {\"success\": False, \"error\": \"Content analysis failed - cannot generate quiz\"}\n",
        "\n",
        "        relevant_content = \"\\n\\n\".join(content_chunks[:5])\n",
        "        topic = analysis.get(\"topic\", \"Educational Content\")\n",
        "\n",
        "        # Enhanced prompt with better error handling\n",
        "        messages = [{\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"\"\"You are an expert educator creating a multiple-choice quiz.\n",
        "\n",
        "            Create EXACTLY {num_questions} multiple-choice questions based on the provided content.\n",
        "            \n",
        "            IMPORTANT: All questions should be at {difficulty_level.upper()} difficulty level.\n",
        "            \n",
        "            Difficulty Guidelines:\n",
        "            - EASY: Basic recall, definitions, simple concepts\n",
        "            - MEDIUM: Understanding, application, connections between concepts  \n",
        "            - HARD: Analysis, synthesis, complex reasoning, edge cases\n",
        "            \n",
        "            Each question MUST have:\n",
        "            - A clear, specific question appropriate for {difficulty_level} level\n",
        "            - Exactly 4 options (A, B, C, D)\n",
        "            - One correct answer (index 0-3)\n",
        "            - A brief explanation of why the answer is correct\n",
        "            - Difficulty level matching the requested {difficulty_level} level\n",
        "\n",
        "            Focus on testing understanding of the provided content, not general knowledge.\n",
        "\n",
        "            CRITICAL: You must generate exactly {num_questions} questions. Do not generate fewer.\n",
        "\n",
        "            Respond in JSON format matching this EXACT structure:\n",
        "            {{\n",
        "                \"questions\": [\n",
        "                    {{\n",
        "                        \"question\": \"What is...?\",\n",
        "                        \"options\": [\"Option A\", \"Option B\", \"Option C\", \"Option D\"],\n",
        "                        \"correct_answer\": 0,\n",
        "                        \"explanation\": \"Brief explanation...\",\n",
        "                        \"difficulty\": \"{difficulty_level}\"\n",
        "                    }}\n",
        "                ],\n",
        "                \"topic\": \"{topic}\",\n",
        "                \"total_questions\": {num_questions}\n",
        "            }}\"\"\"\n",
        "        }, {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"Create a {num_questions}-question {difficulty_level} difficulty quiz from this content:\\n\\n{relevant_content[:3000]}\"\n",
        "        }]\n",
        "\n",
        "        response = self.llm.make_call(messages, {\"type\": \"json_object\"})\n",
        "        \n",
        "        if not response[\"success\"]:\n",
        "            return {\"success\": False, \"error\": f\"Quiz generation LLM call failed: {response['error']}\"}\n",
        "\n",
        "        try:\n",
        "            quiz_data = json.loads(response[\"content\"])\n",
        "            \n",
        "            # Validate the response structure\n",
        "            if \"questions\" not in quiz_data:\n",
        "                return {\"success\": False, \"error\": \"LLM response missing 'questions' field\"}\n",
        "            \n",
        "            questions = quiz_data[\"questions\"]\n",
        "            if not questions or len(questions) == 0:\n",
        "                return {\"success\": False, \"error\": \"LLM generated no questions\"}\n",
        "            \n",
        "            if len(questions) < num_questions:\n",
        "                return {\"success\": False, \"error\": f\"LLM generated only {len(questions)} questions, expected {num_questions}\"}\n",
        "            \n",
        "            # Validate each question structure\n",
        "            for i, q in enumerate(questions):\n",
        "                required_fields = [\"question\", \"options\", \"correct_answer\", \"explanation\"]\n",
        "                for field in required_fields:\n",
        "                    if field not in q:\n",
        "                        return {\"success\": False, \"error\": f\"Question {i+1} missing field: {field}\"}\n",
        "                \n",
        "                if not isinstance(q[\"options\"], list) or len(q[\"options\"]) != 4:\n",
        "                    return {\"success\": False, \"error\": f\"Question {i+1} must have exactly 4 options\"}\n",
        "                \n",
        "                if not isinstance(q[\"correct_answer\"], int) or q[\"correct_answer\"] < 0 or q[\"correct_answer\"] > 3:\n",
        "                    return {\"success\": False, \"error\": f\"Question {i+1} has invalid correct_answer index\"}\n",
        "            \n",
        "            # Create quiz object with all required fields\n",
        "            quiz_data_complete = {\n",
        "                \"questions\": quiz_data[\"questions\"],\n",
        "                \"topic\": quiz_data.get(\"topic\", \"Educational Content\"),\n",
        "                \"total_questions\": quiz_data.get(\"total_questions\", len(quiz_data[\"questions\"])),\n",
        "                \"difficulty_level\": difficulty_level,\n",
        "                \"created_by\": professor_name,\n",
        "                \"created_at\": datetime.now()\n",
        "            }\n",
        "            \n",
        "            quiz = QuizContent(**quiz_data_complete)\n",
        "            \n",
        "            return {\"success\": True, \"quiz\": quiz}\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            return {\"success\": False, \"error\": f\"Failed to parse quiz JSON: {str(e)}\"}\n",
        "        except Exception as e:\n",
        "            return {\"success\": False, \"error\": f\"Quiz creation failed: {str(e)}\"}\n",
        "\n",
        "# ======================== HYBRID SYSTEM COORDINATOR ========================\n",
        "\n",
        "class HybridEducationalSystem:\n",
        "    \"\"\" Centralized Agent Coordinator \"\"\"\n",
        "    def __init__(self, api_key: str):\n",
        "        self.llm = LLMInterface(api_key)\n",
        "        self.document_processor = DocumentProcessorAgent()\n",
        "        self.vector_store_agent = VectorStore(api_key)\n",
        "        self.content_analyzer = ContentAnalyzerAgent(self.llm)\n",
        "        self.quiz_generator = QuizGeneratorAgent(self.llm)\n",
        "\n",
        "    def process_document(self, file_path: str, file_type: str, num_questions: int = 5, \n",
        "                        difficulty_level: str = \"medium\", professor_name: str = \"Professor\") -> Dict:\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Create status containers for real-time updates\n",
        "        status_container = st.empty()\n",
        "        progress_bar = st.progress(0)\n",
        "\n",
        "        try:\n",
        "            # Step 1: Document Processing Agent\n",
        "            status_container.info(\"🤖 **Agent 1: DocumentProcessorAgent** - Extracting text from your document...\")\n",
        "            progress_bar.progress(0.15)\n",
        "\n",
        "            extraction_result = self.document_processor.extract_text_from_file(file_path, file_type)\n",
        "            \n",
        "            if not extraction_result[\"success\"]:\n",
        "                status_container.error(f\"❌ **Document Extraction Failed** - {extraction_result['error']}\")\n",
        "                progress_bar.progress(0)\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"error\": \"document_extraction_failed\",\n",
        "                    \"details\": extraction_result[\"error\"],\n",
        "                    \"metrics\": self.llm.get_metrics()\n",
        "                }\n",
        "\n",
        "            text_content = extraction_result[\"text\"]\n",
        "\n",
        "            # Step 1.5 - Validate content quality\n",
        "            status_container.info(\"🔍 **Validating Content Quality** - Checking if document is suitable for quiz generation...\")\n",
        "            progress_bar.progress(0.25)\n",
        "\n",
        "            validation_result = self.document_processor.validate_content_quality(text_content)\n",
        "\n",
        "            if not validation_result[\"is_valid\"]:\n",
        "                status_container.error(f\"❌ **Content Validation Failed** - {validation_result['error']}\")\n",
        "                progress_bar.progress(0)\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"error\": \"insufficient_content\",\n",
        "                    \"validation_error\": validation_result[\"error\"],\n",
        "                    \"suggestion\": validation_result[\"suggestion\"],\n",
        "                    \"metrics\": self.llm.get_metrics()\n",
        "                }\n",
        "\n",
        "            status_container.success(f\"✅ **Content Validated** - {validation_result['message']}\")\n",
        "\n",
        "            chunks = self.document_processor.chunk_text(text_content)\n",
        "            if not chunks:\n",
        "                status_container.error(\"❌ **Text Chunking Failed** - Unable to create content chunks\")\n",
        "                progress_bar.progress(0)\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"error\": \"chunking_failed\",\n",
        "                    \"details\": \"No text chunks could be created\",\n",
        "                    \"metrics\": self.llm.get_metrics()\n",
        "                }\n",
        "\n",
        "            status_container.success(f\"✅ **Agent 1 Complete** - Created {len(chunks)} text chunks (0 LLM calls)\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            # Step 2: Vector Store Agent\n",
        "            status_container.info(\"🔍 **VectorStore** - Creating semantic search index...\")\n",
        "            progress_bar.progress(0.40)\n",
        "\n",
        "            vector_result = self.vector_store_agent.create_vector_store(chunks)\n",
        "            if not vector_result[\"success\"]:\n",
        "                status_container.error(f\"❌ **Vector Store Creation Failed** - {vector_result['error']}\")\n",
        "                progress_bar.progress(0)\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"error\": \"vector_store_failed\",\n",
        "                    \"details\": vector_result[\"error\"],\n",
        "                    \"metrics\": self.llm.get_metrics()\n",
        "                }\n",
        "\n",
        "            status_container.success(\"✅ **Vector embeddings ready** (0 LLM calls)\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            # Step 3: Content Analyzer Agent\n",
        "            status_container.info(\"🤖 **Agent 2: ContentAnalyzerAgent** - Analyzing content structure...\")\n",
        "            progress_bar.progress(0.65)\n",
        "\n",
        "            relevant_chunks = self.vector_store_agent.retrieve_relevant_content(\"main concepts key topics\", k=5)\n",
        "            if not relevant_chunks:\n",
        "                status_container.error(\"❌ **Content Retrieval Failed** - No relevant content chunks found\")\n",
        "                progress_bar.progress(0)\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"error\": \"content_retrieval_failed\",\n",
        "                    \"details\": \"Unable to retrieve relevant content for analysis\",\n",
        "                    \"metrics\": self.llm.get_metrics()\n",
        "                }\n",
        "\n",
        "            analysis_result = self.content_analyzer.analyze_content_for_quiz(relevant_chunks)\n",
        "            \n",
        "            if not analysis_result[\"success\"]:\n",
        "                status_container.error(f\"❌ **Content Analysis Failed** - {analysis_result['error']}\")\n",
        "                progress_bar.progress(0)\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"error\": \"content_analysis_failed\",\n",
        "                    \"details\": analysis_result[\"error\"],\n",
        "                    \"metrics\": self.llm.get_metrics()\n",
        "                }\n",
        "\n",
        "            status_container.success(f\"✅ **Agent 2 Complete** - Identified topic: '{analysis_result['topic']}' (1 LLM call)\")\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            # Step 4: Quiz Generator Agent\n",
        "            status_container.info(f\"🤖 **Agent 3: QuizGeneratorAgent** - Creating {difficulty_level.upper()} difficulty questions...\")\n",
        "            progress_bar.progress(0.90)\n",
        "\n",
        "            quiz_chunks = self.vector_store_agent.retrieve_relevant_content(\"important information facts\", k=5)\n",
        "            if not quiz_chunks:\n",
        "                status_container.error(\"❌ **Quiz Content Retrieval Failed** - No content available for quiz generation\")\n",
        "                progress_bar.progress(0)\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"error\": \"quiz_content_retrieval_failed\",\n",
        "                    \"details\": \"Unable to retrieve content for quiz questions\",\n",
        "                    \"metrics\": self.llm.get_metrics()\n",
        "                }\n",
        "\n",
        "            quiz_result = self.quiz_generator.generate_quiz(quiz_chunks, analysis_result, num_questions, difficulty_level, professor_name)\n",
        "            \n",
        "            if not quiz_result[\"success\"]:\n",
        "                status_container.error(f\"❌ **Quiz Generation Failed** - {quiz_result['error']}\")\n",
        "                progress_bar.progress(0)\n",
        "                return {\n",
        "                    \"success\": False,\n",
        "                    \"error\": \"quiz_generation_failed\",\n",
        "                    \"details\": quiz_result[\"error\"],\n",
        "                    \"metrics\": self.llm.get_metrics()\n",
        "                }\n",
        "\n",
        "            # Calculate metrics\n",
        "            processing_time = time.time() - start_time\n",
        "            metrics = self.llm.get_metrics()\n",
        "\n",
        "            # Final status\n",
        "            progress_bar.progress(1.0)\n",
        "            status_container.success(f\"🎉 **All Agents Complete!** - Created {difficulty_level.upper()} quiz with {metrics['total_calls']} LLM calls, ${metrics['total_cost']:.4f} cost, {processing_time:.1f}s\")\n",
        "\n",
        "            return {\n",
        "                \"success\": True,\n",
        "                \"quiz\": quiz_result[\"quiz\"],\n",
        "                \"analysis\": analysis_result,\n",
        "                \"processing_time\": round(processing_time, 2),\n",
        "                \"metrics\": metrics\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            status_container.error(f\"❌ **Processing Failed** - {str(e)}\")\n",
        "            progress_bar.progress(0)\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"error\": \"unexpected_error\",\n",
        "                \"details\": str(e),\n",
        "                \"metrics\": self.llm.get_metrics()\n",
        "            }\n",
        "\n",
        "# ======================== AUTHENTICATION UI ========================\n",
        "\n",
        "def display_login_interface(auth_manager: AuthenticationManager):\n",
        "    \"\"\"Display login interface\"\"\"\n",
        "    st.markdown(\"## 🔐 Login to Quiz System\")\n",
        "    \n",
        "    # Check if we're accessing a shared quiz\n",
        "    try:\n",
        "        # Try the newer method first\n",
        "        query_params = st.query_params\n",
        "    except AttributeError:\n",
        "        # Fall back to the older method\n",
        "        query_params = st.experimental_get_query_params()\n",
        "    \n",
        "    if 'quiz_session' in query_params:\n",
        "        session_id = query_params['quiz_session']\n",
        "        if isinstance(session_id, list):\n",
        "            session_id = session_id[0]  # Handle list format from older Streamlit versions\n",
        "        session_data = auth_manager.get_quiz_session(session_id)\n",
        "        \n",
        "        if session_data:\n",
        "            st.info(f\"📝 **Accessing Shared Quiz** created by {session_data['created_by']}\")\n",
        "            st.markdown(\"Please login to take the quiz:\")\n",
        "        else:\n",
        "            st.error(\"❌ **Invalid or Expired Quiz Link**\")\n",
        "            st.markdown(\"The quiz session has expired or the link is invalid.\")\n",
        "            return None, None\n",
        "    \n",
        "    # Create login form\n",
        "    with st.container():\n",
        "        col1, col2, col3 = st.columns([1, 2, 1])\n",
        "        \n",
        "        with col2:\n",
        "            st.markdown(\"\"\"\n",
        "            <div style=\"background: white; padding: 2rem; border-radius: 10px; box-shadow: 0 4px 12px rgba(0,0,0,0.1);\">\n",
        "            \"\"\", unsafe_allow_html=True)\n",
        "            \n",
        "            with st.form(\"login_form\"):\n",
        "                st.markdown(\"### Please Login\")\n",
        "                \n",
        "                username = st.text_input(\"👤 Username:\", placeholder=\"Enter your username\")\n",
        "                password = st.text_input(\"🔒 Password:\", type=\"password\", placeholder=\"Enter your password\")\n",
        "                \n",
        "                submit_button = st.form_submit_button(\"🚀 Login\", type=\"primary\", use_container_width=True)\n",
        "                \n",
        "                if submit_button:\n",
        "                    if not username or not password:\n",
        "                        st.error(\"❌ Please enter both username and password\")\n",
        "                    else:\n",
        "                        user_info = auth_manager.authenticate_user(username, password)\n",
        "                        if user_info:\n",
        "                            # Store user info in session state\n",
        "                            st.session_state.authenticated = True\n",
        "                            st.session_state.user_info = user_info\n",
        "                            st.success(f\"✅ Welcome, {user_info['full_name']}!\")\n",
        "                            \n",
        "                            # Check if accessing shared quiz\n",
        "                            try:\n",
        "                                # Try the newer method first\n",
        "                                query_params = st.query_params\n",
        "                            except AttributeError:\n",
        "                                # Fall back to the older method\n",
        "                                query_params = st.experimental_get_query_params()\n",
        "                            \n",
        "                            if 'quiz_session' in query_params:\n",
        "                                session_id = query_params['quiz_session']\n",
        "                                if isinstance(session_id, list):\n",
        "                                    session_id = session_id[0]  # Handle list format\n",
        "                                session_data = auth_manager.get_quiz_session(session_id)\n",
        "                                if session_data:\n",
        "                                    st.session_state.shared_quiz_data = session_data\n",
        "                            \n",
        "                            time.sleep(1)\n",
        "                            st.rerun()\n",
        "                        else:\n",
        "                            st.error(\"❌ Invalid username or password\")\n",
        "            \n",
        "            st.markdown(\"</div>\", unsafe_allow_html=True)\n",
        "    \n",
        "    # Demo accounts information\n",
        "    st.markdown(\"---\")\n",
        "    st.markdown(\"### 🎯 Demo Accounts\")\n",
        "    \n",
        "    col1, col2 = st.columns(2)\n",
        "    \n",
        "    with col1:\n",
        "        st.markdown(\"\"\"\n",
        "        **👨‍🏫 Professor Accounts:**\n",
        "        - Username: `prof_smith` | Password: `password123`\n",
        "        - Username: `prof_jones` | Password: `password123`\n",
        "        \"\"\")\n",
        "    \n",
        "    with col2:\n",
        "        st.markdown(\"\"\"\n",
        "        **👨‍🎓 Student Accounts:**\n",
        "        - Username: `student_alice` | Password: `password123`\n",
        "        - Username: `student_bob` | Password: `password123`\n",
        "        - Username: `student_charlie` | Password: `password123`\n",
        "        \"\"\")\n",
        "    \n",
        "    return None, None\n",
        "\n",
        "def display_logout_button():\n",
        "    \"\"\"Display logout button in sidebar\"\"\"\n",
        "    if st.sidebar.button(\"🚪 Logout\", type=\"secondary\"):\n",
        "        # Clear all session state\n",
        "        for key in list(st.session_state.keys()):\n",
        "            del st.session_state[key]\n",
        "        st.rerun()\n",
        "\n",
        "def display_user_info():\n",
        "    \"\"\"Display current user info in sidebar\"\"\"\n",
        "    if 'user_info' in st.session_state:\n",
        "        user_info = st.session_state.user_info\n",
        "        role_emoji = \"👨‍🏫\" if user_info['role'] == 'professor' else \"👨‍🎓\"\n",
        "        \n",
        "        st.sidebar.markdown(\"### 👤 Current User\")\n",
        "        st.sidebar.markdown(f\"\"\"\n",
        "        {role_emoji} **{user_info['full_name']}**  \n",
        "        📋 Role: {user_info['role'].title()}  \n",
        "        🔑 Username: {user_info['username']}\n",
        "        \"\"\")\n",
        "\n",
        "# ======================== ROLE-BASED INTERFACES ========================\n",
        "\n",
        "def display_professor_interface(edu_system, auth_manager):\n",
        "    \"\"\"Professor interface for creating quizzes\"\"\"\n",
        "    st.markdown(\"## 👨‍🏫 Professor Dashboard\")\n",
        "    st.markdown(\"Upload educational content to generate interactive quizzes for your students.\")\n",
        "    \n",
        "    # Quiz creation section\n",
        "    with st.container():\n",
        "        st.markdown(\"### 📁 Create New Quiz\")\n",
        "        \n",
        "        col1, col2 = st.columns([2, 1])\n",
        "        \n",
        "        with col1:\n",
        "            uploaded_file = st.file_uploader(\n",
        "                \"Upload educational document:\",\n",
        "                type=['pdf', 'docx', 'txt'],\n",
        "                help=\"Upload PDF, DOCX, or TXT files containing educational content\"\n",
        "            )\n",
        "        \n",
        "        with col2:\n",
        "            num_questions = st.slider(\n",
        "                \"Number of questions:\",\n",
        "                min_value=Config.MIN_QUIZ_QUESTIONS,\n",
        "                max_value=Config.MAX_QUIZ_QUESTIONS,\n",
        "                value=5\n",
        "            )\n",
        "            \n",
        "            difficulty_level = st.selectbox(\n",
        "                \"Quiz difficulty:\",\n",
        "                options=[\"easy\", \"medium\", \"hard\"],\n",
        "                index=1,\n",
        "                format_func=lambda x: f\"📈 {x.title()}\"\n",
        "            )\n",
        "        \n",
        "        if uploaded_file:\n",
        "            st.success(f\"📄 File ready: **{uploaded_file.name}**\")\n",
        "            \n",
        "            # Quiz generation button\n",
        "            if st.button(\"🚀 Generate Quiz for Students\", type=\"primary\", use_container_width=True):\n",
        "                \n",
        "                professor_name = st.session_state.user_info['full_name']\n",
        "                \n",
        "                # Save file temporarily\n",
        "                with tempfile.NamedTemporaryFile(delete=False, suffix=f\".{uploaded_file.name.split('.')[-1]}\") as tmp_file:\n",
        "                    tmp_file.write(uploaded_file.getvalue())\n",
        "                    file_path = tmp_file.name\n",
        "                \n",
        "                file_type = uploaded_file.name.split('.')[-1].lower()\n",
        "                \n",
        "                # Process with selected difficulty\n",
        "                with st.spinner(f\"🔄 Creating {difficulty_level.upper()} difficulty quiz...\"):\n",
        "                    result = edu_system.process_document(\n",
        "                        file_path=file_path, \n",
        "                        file_type=file_type, \n",
        "                        num_questions=num_questions, \n",
        "                        difficulty_level=difficulty_level, \n",
        "                        professor_name=professor_name\n",
        "                    )\n",
        "                \n",
        "                os.unlink(file_path)\n",
        "                \n",
        "                if result['success']:\n",
        "                    st.success(\"✅ Quiz created successfully!\")\n",
        "                    \n",
        "                    # Store quiz for students\n",
        "                    if 'available_quizzes' not in st.session_state:\n",
        "                        st.session_state.available_quizzes = []\n",
        "                    \n",
        "                    quiz_info = {\n",
        "                        'quiz': result['quiz'],\n",
        "                        'metrics': result['metrics'],\n",
        "                        'processing_time': result['processing_time'],\n",
        "                        'file_name': uploaded_file.name\n",
        "                    }\n",
        "                    st.session_state.available_quizzes.append(quiz_info)\n",
        "                    \n",
        "                    # Store quiz in database for cross-browser access\n",
        "                    session_id = auth_manager.store_quiz_session(\n",
        "                        quiz_info, \n",
        "                        st.session_state.user_info['username']\n",
        "                    )\n",
        "                    \n",
        "                    # Show success message with quiz details and shareable link\n",
        "                    st.balloons()\n",
        "                    st.info(f\"\"\"\n",
        "                    📊 **Quiz Details:**\n",
        "                    - **Topic**: {result['quiz'].topic}\n",
        "                    - **Questions**: {len(result['quiz'].questions)}\n",
        "                    - **Difficulty**: {difficulty_level.title()}\n",
        "                    - **Created by**: {professor_name}\n",
        "                    - **Cost**: ${result['metrics']['total_cost']:.4f}\n",
        "                    \"\"\")\n",
        "                    \n",
        "                    # Generate shareable link using actual ngrok URL if available\n",
        "                    try:\n",
        "                        # Try to get the current ngrok URL from session or environment\n",
        "                        if 'ngrok_url' in st.session_state:\n",
        "                            base_url = st.session_state.ngrok_url\n",
        "                            shareable_link = f\"{base_url}/?quiz_session={session_id}\"\n",
        "                        else:\n",
        "                            # Check if we can detect ngrok\n",
        "                            try:\n",
        "                                import requests\n",
        "                                # Try to get ngrok tunnels\n",
        "                                response = requests.get(\"http://localhost:4040/api/tunnels\")\n",
        "                                tunnels = response.json()\n",
        "                                if tunnels.get('tunnels'):\n",
        "                                    public_url = tunnels['tunnels'][0]['public_url']\n",
        "                                    base_url = public_url\n",
        "                                    st.session_state.ngrok_url = base_url  # Store for future use\n",
        "                                    shareable_link = f\"{base_url}/?quiz_session={session_id}\"\n",
        "                                else:\n",
        "                                    raise Exception(\"No tunnels found\")\n",
        "                            except:\n",
        "                                base_url = \"[YOUR_NGROK_URL]\"\n",
        "                                shareable_link = f\"{base_url}/?quiz_session={session_id}\"\n",
        "                    except:\n",
        "                        base_url = \"[YOUR_NGROK_URL]\"\n",
        "                        shareable_link = f\"{base_url}/?quiz_session={session_id}\"\n",
        "                    \n",
        "                    st.markdown(\"### 🔗 Share Quiz with Students\")\n",
        "                    \n",
        "                    if base_url == \"[YOUR_NGROK_URL]\":\n",
        "                        st.warning(\"⚠️ Replace `[YOUR_NGROK_URL]` with your actual ngrok URL\")\n",
        "                        st.markdown(f\"**Your ngrok URL format:** `https://xxxxx.ngrok-free.app`\")\n",
        "                    \n",
        "                    st.code(shareable_link)\n",
        "                    \n",
        "                    # Show the session ID separately\n",
        "                    st.markdown(\"### 🔑 Session ID\")\n",
        "                    st.code(session_id)\n",
        "                    \n",
        "                    # Instructions\n",
        "                    st.markdown(\"\"\"\n",
        "                    **📋 Instructions for Students:**\n",
        "                    1. **Direct Link**: Use the complete URL above\n",
        "                    2. **Manual**: Go to your app URL and add `?quiz_session=SESSION_ID`\n",
        "                    3. **Login**: Use student credentials (e.g., `student_alice` / `password123`)\n",
        "                    \n",
        "                    **⚠️ Note**: Students might see an ngrok warning page first - they should click \"Visit Site\"\n",
        "                    \"\"\")\n",
        "                    \n",
        "                else:\n",
        "                    # Handle errors with specific messages and helpful suggestions\n",
        "                    st.error(\"❌ **Quiz Generation Failed**\")\n",
        "                    \n",
        "                    error_type = result.get('error', 'unknown_error')\n",
        "                    error_details = result.get('details', 'Unknown error occurred')\n",
        "                    \n",
        "                    if error_type == 'insufficient_content':\n",
        "                        st.warning(f\"**Issue**: {result['validation_error']}\")\n",
        "                        st.info(f\"**Suggestion**: {result['suggestion']}\")\n",
        "                    elif error_type == 'document_extraction_failed':\n",
        "                        st.error(f\"**Document Processing Error**: {error_details}\")\n",
        "                        st.info(\"**Suggestions**: Try a different file format or check if the file is corrupted\")\n",
        "                    elif error_type == 'content_analysis_failed':\n",
        "                        st.error(f\"**Content Analysis Error**: {error_details}\")\n",
        "                        st.info(\"**Suggestions**: Check your internet connection or try with different content\")\n",
        "                    elif error_type == 'quiz_generation_failed':\n",
        "                        st.error(f\"**Quiz Generation Error**: {error_details}\")\n",
        "                        st.info(\"**Suggestions**: Try reducing the number of questions or using different content\")\n",
        "                    else:\n",
        "                        st.error(f\"**Error Details**: {error_details}\")\n",
        "                    \n",
        "                    st.markdown(\"\"\"\n",
        "                    **General troubleshooting:**\n",
        "                    - Ensure your document has sufficient educational content\n",
        "                    - Check your internet connection for API calls\n",
        "                    - Try reducing the number of questions requested\n",
        "                    - Verify the document file is not corrupted\n",
        "                    - Upload content with clear educational structure\n",
        "                    \"\"\")\n",
        "                        \n",
        "                    # Show metrics even for failed attempts\n",
        "                    if 'metrics' in result:\n",
        "                        st.markdown(\"### 📊 Processing Metrics\")\n",
        "                        display_metrics(result['metrics'], 0)\n",
        "\n",
        "def display_student_interface(auth_manager):\n",
        "    \"\"\"Student interface for taking quizzes\"\"\"\n",
        "    st.markdown(\"## 👨‍🎓 Student Dashboard\")\n",
        "    \n",
        "    # Check if accessing a shared quiz\n",
        "    if 'shared_quiz_data' in st.session_state:\n",
        "        st.info(f\"📝 **Shared Quiz** from {st.session_state.shared_quiz_data['created_by']}\")\n",
        "        quiz_data = st.session_state.shared_quiz_data['quiz_data']\n",
        "        \n",
        "        # Convert quiz data back to QuizContent object\n",
        "        try:\n",
        "            quiz_dict = quiz_data['quiz']\n",
        "            \n",
        "            # Ensure datetime is properly handled\n",
        "            if 'created_at' in quiz_dict and isinstance(quiz_dict['created_at'], str):\n",
        "                from datetime import datetime\n",
        "                try:\n",
        "                    quiz_dict['created_at'] = datetime.fromisoformat(quiz_dict['created_at'].replace('Z', '+00:00'))\n",
        "                except:\n",
        "                    quiz_dict['created_at'] = datetime.now()\n",
        "            \n",
        "            quiz = QuizContent(**quiz_dict)\n",
        "            st.session_state.current_quiz = quiz\n",
        "            st.session_state.quiz_mode = \"taking\"\n",
        "            \n",
        "            display_quiz(quiz)\n",
        "            return\n",
        "        except Exception as e:\n",
        "            st.error(f\"❌ **Failed to load shared quiz**: {str(e)}\")\n",
        "            st.markdown(\"Please try accessing the quiz link again or contact your professor.\")\n",
        "            return\n",
        "    \n",
        "    # Check if there are any available quizzes\n",
        "    if 'available_quizzes' not in st.session_state or not st.session_state.available_quizzes:\n",
        "        st.info(\"📚 **No quizzes available yet**\")\n",
        "        st.markdown(\"\"\"\n",
        "        Waiting for your professor to upload educational content and generate quizzes.\n",
        "        \n",
        "        **What you can expect:**\n",
        "        - 🎯 Interactive multiple-choice questions\n",
        "        - ⚡ Instant feedback on your answers\n",
        "        - 💡 Detailed explanations for learning\n",
        "        - 📊 Progress tracking and final scores\n",
        "        \"\"\")\n",
        "        return\n",
        "    \n",
        "    st.markdown(\"### 📋 Available Quizzes\")\n",
        "    \n",
        "    # Display available quizzes\n",
        "    for idx, quiz_info in enumerate(st.session_state.available_quizzes):\n",
        "        quiz = quiz_info['quiz']\n",
        "        \n",
        "        with st.expander(f\"📝 **{quiz.topic}** ({quiz.difficulty_level.value.title()} Level)\", expanded=False):\n",
        "            col1, col2 = st.columns([2, 1])\n",
        "            \n",
        "            with col1:\n",
        "                st.markdown(f\"\"\"\n",
        "                **📚 Quiz Information:**\n",
        "                - **Created by**: {quiz.created_by}\n",
        "                - **Questions**: {quiz.total_questions}\n",
        "                - **Difficulty**: {quiz.difficulty_level.value.title()}\n",
        "                - **Source**: {quiz_info['file_name']}\n",
        "                \"\"\")\n",
        "            \n",
        "            with col2:\n",
        "                if st.button(f\"📝 Take Quiz\", key=f\"take_quiz_{idx}\", type=\"primary\"):\n",
        "                    st.session_state.current_quiz = quiz\n",
        "                    st.session_state.current_quiz_index = idx\n",
        "                    st.session_state.quiz_mode = \"taking\"\n",
        "                    st.rerun()\n",
        "    \n",
        "    # Display quiz if student is taking one\n",
        "    if st.session_state.get('quiz_mode') == 'taking' and 'current_quiz' in st.session_state:\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(\"### 🎯 Quiz in Progress\")\n",
        "        \n",
        "        # Back to quiz list button\n",
        "        if st.button(\"⬅️ Back to Quiz List\", type=\"secondary\"):\n",
        "            st.session_state.quiz_mode = \"browsing\"\n",
        "            st.session_state.pop('current_quiz', None)\n",
        "            # Clear quiz state when going back\n",
        "            for key in list(st.session_state.keys()):\n",
        "                if key.startswith(('quiz_selections', 'quiz_submitted', 'quiz_show_results')):\n",
        "                    del st.session_state[key]\n",
        "            st.rerun()\n",
        "        \n",
        "        display_quiz(st.session_state.current_quiz)\n",
        "\n",
        "# ======================== STREAMLIT UI ========================\n",
        "\n",
        "def setup_colab_tunnel():\n",
        "    \"\"\"Setup instructions and helper for Colab tunneling\"\"\"\n",
        "    if 'colab_tunnel_setup' not in st.session_state:\n",
        "        st.session_state.colab_tunnel_setup = False\n",
        "\n",
        "    \"\"\" Get API key \"\"\"\n",
        "    try:\n",
        "        from google.colab import userdata\n",
        "        api_key = userdata.get('OPENAI_API_KEY')\n",
        "        return api_key\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "def create_beautiful_ui():\n",
        "    \"\"\" Setup beautiful UI \"\"\"\n",
        "    st.set_page_config(\n",
        "        page_title=\"🎓 AI Quiz Generator\",\n",
        "        page_icon=\"🎓\",\n",
        "        layout=\"wide\"\n",
        "    )\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .main-header {\n",
        "        background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);\n",
        "        padding: 2.5rem 2rem;\n",
        "        border-radius: 20px;\n",
        "        color: white;\n",
        "        text-align: center;\n",
        "        margin-bottom: 1.5rem;\n",
        "        position: relative;\n",
        "        overflow: hidden;\n",
        "        box-shadow: 0 10px 40px rgba(102, 126, 234, 0.3);\n",
        "    }\n",
        "\n",
        "    .creative-title {\n",
        "        font-size: 3.5rem;\n",
        "        font-weight: 800;\n",
        "        margin: 0;\n",
        "        color: #ffffff;\n",
        "        text-shadow: 0 4px 20px rgba(0,0,0,0.3);\n",
        "        letter-spacing: -2px;\n",
        "    }\n",
        "\n",
        "    .metric-card {\n",
        "        background: linear-gradient(145deg, #2d3748, #4a5568);\n",
        "        border-radius: 16px;\n",
        "        padding: 1.5rem;\n",
        "        margin: 0.5rem;\n",
        "        box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);\n",
        "        border: 1px solid rgba(255, 255, 255, 0.1);\n",
        "        position: relative;\n",
        "        overflow: hidden;\n",
        "    }\n",
        "\n",
        "    .metric-card::before {\n",
        "        content: '';\n",
        "        position: absolute;\n",
        "        top: 0;\n",
        "        left: 0;\n",
        "        right: 0;\n",
        "        height: 3px;\n",
        "        background: linear-gradient(90deg, #667eea, #764ba2);\n",
        "    }\n",
        "\n",
        "    .metric-icon {\n",
        "        font-size: 1.8rem;\n",
        "        margin-bottom: 0.5rem;\n",
        "        display: block;\n",
        "    }\n",
        "\n",
        "    .metric-label {\n",
        "        color: #a0aec0;\n",
        "        font-size: 0.85rem;\n",
        "        font-weight: 500;\n",
        "        margin: 0;\n",
        "        text-transform: uppercase;\n",
        "        letter-spacing: 0.5px;\n",
        "    }\n",
        "\n",
        "    .metric-value {\n",
        "        color: #ffffff;\n",
        "        font-size: 1.8rem;\n",
        "        font-weight: 700;\n",
        "        margin: 0.3rem 0 0 0;\n",
        "        line-height: 1.2;\n",
        "    }\n",
        "\n",
        "    .metric-trend {\n",
        "        color: #68d391;\n",
        "        font-size: 0.75rem;\n",
        "        margin-top: 0.25rem;\n",
        "    }\n",
        "    \n",
        "    .role-badge {\n",
        "        display: inline-block;\n",
        "        padding: 0.25rem 0.75rem;\n",
        "        border-radius: 20px;\n",
        "        font-size: 0.8rem;\n",
        "        font-weight: 600;\n",
        "        margin-left: 0.5rem;\n",
        "    }\n",
        "    \n",
        "    .professor-badge {\n",
        "        background: #667eea;\n",
        "        color: white;\n",
        "    }\n",
        "    \n",
        "    .student-badge {\n",
        "        background: #48bb78;\n",
        "        color: white;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "def display_metrics(metrics: Dict, processing_time: float = 0):\n",
        "    \"\"\"Display beautiful performance metrics cards\"\"\"\n",
        "    col1, col2, col3, col4 = st.columns(4)\n",
        "\n",
        "    with col1:\n",
        "        st.markdown(f\"\"\"\n",
        "        <div class=\"metric-card\">\n",
        "            <div class=\"metric-icon\">🔥</div>\n",
        "            <p class=\"metric-label\">Total LLM Calls</p>\n",
        "            <h2 class=\"metric-value\">{metrics.get('total_calls', 0)}</h2>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with col2:\n",
        "        cost = metrics.get('total_cost', 0)\n",
        "        st.markdown(f\"\"\"\n",
        "        <div class=\"metric-card\">\n",
        "            <div class=\"metric-icon\">💰</div>\n",
        "            <p class=\"metric-label\">Total Cost</p>\n",
        "            <h2 class=\"metric-value\">${cost:.4f}</h2>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with col3:\n",
        "        avg_cost = metrics.get('average_cost_per_call', 0)\n",
        "        st.markdown(f\"\"\"\n",
        "        <div class=\"metric-card\">\n",
        "            <div class=\"metric-icon\">📊</div>\n",
        "            <p class=\"metric-label\">Average Cost</p>\n",
        "            <h2 class=\"metric-value\">${avg_cost:.4f}</h2>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    with col4:\n",
        "        st.markdown(f\"\"\"\n",
        "        <div class=\"metric-card\">\n",
        "            <div class=\"metric-icon\">⏱️</div>\n",
        "            <p class=\"metric-label\">Processing Time</p>\n",
        "            <h2 class=\"metric-value\">{processing_time:.1f}s</h2>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "def display_quiz(quiz: QuizContent):\n",
        "    \"\"\"Display the interactive quiz with difficulty indication\"\"\"\n",
        "    if not quiz or not quiz.questions:\n",
        "        st.error(\"❌ No quiz questions generated\")\n",
        "        return\n",
        "\n",
        "    # Quiz header with difficulty and creator info\n",
        "    difficulty_color = {\n",
        "        \"easy\": \"#48bb78\",\n",
        "        \"medium\": \"#ed8936\", \n",
        "        \"hard\": \"#e53e3e\"\n",
        "    }\n",
        "    \n",
        "    st.markdown(f\"\"\"\n",
        "    <div style=\"background: white; padding: 2rem; border-radius: 12px; box-shadow: 0 4px 12px rgba(0,0,0,0.1); margin: 1rem 0;\">\n",
        "        <h2 style=\"color: #2d3748; margin: 0 0 1rem 0;\">📝 Quiz: {quiz.topic}</h2>\n",
        "        <div style=\"display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;\">\n",
        "            <p style=\"color: #4a5568; margin: 0;\"><strong>Total Questions:</strong> {len(quiz.questions)}</p>\n",
        "            <div style=\"display: flex; gap: 1rem;\">\n",
        "                <span style=\"background: {difficulty_color.get(quiz.difficulty_level.value, '#ed8936')}; color: white; padding: 0.25rem 0.75rem; border-radius: 15px; font-size: 0.9rem; font-weight: 600;\">\n",
        "                    📈 {quiz.difficulty_level.value.title()} Level\n",
        "                </span>\n",
        "                <span style=\"background: #667eea; color: white; padding: 0.25rem 0.75rem; border-radius: 15px; font-size: 0.9rem;\">\n",
        "                    👨‍🏫 {quiz.created_by}\n",
        "                </span>\n",
        "            </div>\n",
        "        </div>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # Initialize session state\n",
        "    if 'quiz_selections' not in st.session_state:\n",
        "        st.session_state.quiz_selections = {}\n",
        "    if 'quiz_submitted' not in st.session_state:\n",
        "        st.session_state.quiz_submitted = set()\n",
        "    if 'quiz_show_results' not in st.session_state:\n",
        "        st.session_state.quiz_show_results = {}\n",
        "\n",
        "    # Display each question\n",
        "    for i, question in enumerate(quiz.questions):\n",
        "        st.markdown(\"---\")\n",
        "        st.markdown(f\"### Question {i+1}\")\n",
        "        \n",
        "        # Show question difficulty\n",
        "        q_difficulty_color = difficulty_color.get(question.difficulty.value, '#ed8936')\n",
        "        st.markdown(f\"\"\"\n",
        "        <div style=\"display: flex; justify-content: space-between; align-items: center; margin-bottom: 1rem;\">\n",
        "            <span style=\"font-weight: 600; font-size: 1.1rem;\">{question.question}</span>\n",
        "            <span style=\"background: {q_difficulty_color}; color: white; padding: 0.2rem 0.6rem; border-radius: 12px; font-size: 0.8rem;\">\n",
        "                {question.difficulty.value.title()}\n",
        "            </span>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "        question_submitted = i in st.session_state.quiz_submitted\n",
        "\n",
        "        if not question_submitted:\n",
        "            # Selection phase\n",
        "            st.markdown(\"**Click on your answer:**\")\n",
        "\n",
        "            for j, option in enumerate(question.options):\n",
        "                option_letter = chr(65 + j)\n",
        "                option_text = f\"{option_letter}. {option}\"\n",
        "                is_selected = st.session_state.quiz_selections.get(i) == j\n",
        "                button_type = \"primary\" if is_selected else \"secondary\"\n",
        "                button_label = f\"{'🔘' if is_selected else '⚪'} {option_text}\"\n",
        "\n",
        "                if st.button(button_label, key=f\"option_q{i}_choice{j}\", type=button_type, use_container_width=True):\n",
        "                    st.session_state.quiz_selections[i] = j\n",
        "                    st.rerun()\n",
        "\n",
        "            # Submit button\n",
        "            if i in st.session_state.quiz_selections:\n",
        "                selected_option = st.session_state.quiz_selections[i]\n",
        "                selected_text = f\"{chr(65+selected_option)}. {question.options[selected_option]}\"\n",
        "                st.info(f\"💭 **You selected:** {selected_text}\")\n",
        "\n",
        "                col1, col2, col3 = st.columns([1, 1, 1])\n",
        "                with col2:\n",
        "                    if st.button(\"✅ Submit Answer\", key=f\"submit_btn_{i}\", type=\"primary\", use_container_width=True):\n",
        "                        st.session_state.quiz_submitted.add(i)\n",
        "                        st.session_state.quiz_show_results[i] = selected_option\n",
        "                        st.rerun()\n",
        "            else:\n",
        "                st.warning(\"👆 Please select an option above\")\n",
        "\n",
        "        else:\n",
        "            # Results phase\n",
        "            user_answer = st.session_state.quiz_show_results[i]\n",
        "            selected_text = f\"{chr(65+user_answer)}. {question.options[user_answer]}\"\n",
        "            st.markdown(f\"**Your answer:** {selected_text}\")\n",
        "\n",
        "            if user_answer == question.correct_answer:\n",
        "                st.success(\"🎉 **Correct!**\")\n",
        "                st.info(f\"💡 **Explanation:** {question.explanation}\")\n",
        "            else:\n",
        "                correct_option = f\"{chr(65+question.correct_answer)}. {question.options[question.correct_answer]}\"\n",
        "                st.error(\"❌ **Incorrect**\")\n",
        "                st.warning(f\"✅ **Correct Answer:** {correct_option}\")\n",
        "                st.info(f\"💡 **Explanation:** {question.explanation}\")\n",
        "\n",
        "            col1, col2, col3 = st.columns([1, 1, 1])\n",
        "            with col2:\n",
        "                if st.button(\"🔄 Try Again\", key=f\"retry_btn_{i}\", type=\"secondary\"):\n",
        "                    st.session_state.quiz_submitted.discard(i)\n",
        "                    if i in st.session_state.quiz_show_results:\n",
        "                        del st.session_state.quiz_show_results[i]\n",
        "                    st.rerun()\n",
        "\n",
        "    # Progress and final score\n",
        "    total_submitted = len(st.session_state.quiz_submitted)\n",
        "\n",
        "    if total_submitted > 0:\n",
        "        progress = total_submitted / len(quiz.questions)\n",
        "        st.progress(progress)\n",
        "        st.caption(f\"📊 Progress: {total_submitted}/{len(quiz.questions)} questions completed\")\n",
        "\n",
        "        if total_submitted == len(quiz.questions):\n",
        "            correct_count = sum(\n",
        "                1 for i in range(len(quiz.questions))\n",
        "                if st.session_state.quiz_show_results.get(i) == quiz.questions[i].correct_answer\n",
        "            )\n",
        "\n",
        "            score_percentage = (correct_count / len(quiz.questions)) * 100\n",
        "\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"## 🏆 Quiz Complete!\")\n",
        "\n",
        "            col1, col2, col3 = st.columns([1, 2, 1])\n",
        "            with col2:\n",
        "                if score_percentage >= 80:\n",
        "                    st.balloons()\n",
        "                    st.success(f\"🎉 **Outstanding!** {correct_count}/{len(quiz.questions)} ({score_percentage:.0f}%)\")\n",
        "                elif score_percentage >= 60:\n",
        "                    st.info(f\"👍 **Well Done!** {correct_count}/{len(quiz.questions)} ({score_percentage:.0f}%)\")\n",
        "                else:\n",
        "                    st.warning(f\"📚 **Keep Learning!** {correct_count}/{len(quiz.questions)} ({score_percentage:.0f}%)\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function with authentication and role-based access control\"\"\"\n",
        "\n",
        "    create_beautiful_ui()\n",
        "    \n",
        "    # Initialize authentication manager\n",
        "    if 'auth_manager' not in st.session_state:\n",
        "        st.session_state.auth_manager = AuthenticationManager()\n",
        "    \n",
        "    auth_manager = st.session_state.auth_manager\n",
        "\n",
        "    # Check if user is authenticated\n",
        "    if not st.session_state.get('authenticated', False):\n",
        "        # Show header for login page\n",
        "        st.markdown(f\"\"\"\n",
        "        <div class=\"main-header\">\n",
        "            <h1 class=\"creative-title\">🎓 AI Quiz Generator</h1>\n",
        "            <p style=\"font-size: 1.3rem; margin: 1rem 0 0 0;\">Transform educational content into interactive learning experiences</p>\n",
        "            <p style=\"font-size: 0.9rem; margin-top: 0.5rem; font-style: italic;\">✨ Powered by Multi-Agent AI System • ⚡ Instant Feedback • 🎯 Personalized Quizzes</p>\n",
        "        </div>\n",
        "        \"\"\", unsafe_allow_html=True)\n",
        "        \n",
        "        display_login_interface(auth_manager)\n",
        "        return\n",
        "\n",
        "    # User is authenticated - show sidebar with user info and logout\n",
        "    display_user_info()\n",
        "    display_logout_button()\n",
        "    \n",
        "    # Show header with user role\n",
        "    user_role = st.session_state.user_info['role']\n",
        "    role_display = \"👨‍🏫 Professor\" if user_role == 'professor' else \"👨‍🎓 Student\"\n",
        "    badge_class = \"professor-badge\" if user_role == 'professor' else \"student-badge\"\n",
        "\n",
        "    st.markdown(f\"\"\"\n",
        "    <div class=\"main-header\">\n",
        "        <h1 class=\"creative-title\">🎓 AI Quiz Generator</h1>\n",
        "        <span class=\"role-badge {badge_class}\">{role_display}</span>\n",
        "        <p style=\"font-size: 1.3rem; margin: 1rem 0 0 0;\">Transform educational content into interactive learning experiences</p>\n",
        "        <p style=\"font-size: 0.9rem; margin-top: 0.5rem; font-style: italic;\">✨ Powered by Multi-Agent AI System • ⚡ Instant Feedback • 🎯 Personalized Quizzes</p>\n",
        "    </div>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "    # Get and validate API key\n",
        "    if 'openai_key' not in st.session_state:\n",
        "        api_key = setup_colab_tunnel()\n",
        "\n",
        "        if not api_key:\n",
        "            st.error(\"❌ OpenAI API key not found in Colab secrets\")\n",
        "            st.markdown(\"\"\"\n",
        "            **Setup Required:**\n",
        "            1. 🔑 Click key icon in Colab sidebar\n",
        "            2. Add: `OPENAI_API_KEY` = `sk-your-key`\n",
        "            3. Enable \"Notebook access\"\n",
        "            4. **Restart runtime**\n",
        "            \"\"\")\n",
        "            return\n",
        "\n",
        "        if not api_key.startswith('sk-'):\n",
        "            st.error(\"❌ Invalid API key format\")\n",
        "            return\n",
        "\n",
        "        # Test and store API key\n",
        "        try:\n",
        "            test_client = openai.OpenAI(api_key=api_key)\n",
        "            test_client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": \"test\"}],\n",
        "                max_tokens=1\n",
        "            )\n",
        "            st.session_state.openai_key = api_key\n",
        "        except Exception as e:\n",
        "            st.error(f\"❌ API key validation failed: {str(e)}\")\n",
        "            return\n",
        "\n",
        "    # Initialize system\n",
        "    if 'edu_system' not in st.session_state:\n",
        "        try:\n",
        "            with st.spinner(\"🔧 Initializing AI system...\"):\n",
        "                st.session_state.edu_system = HybridEducationalSystem(st.session_state.openai_key)\n",
        "            st.success(\"✅ System ready!\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"❌ System initialization failed: {str(e)}\")\n",
        "            return\n",
        "\n",
        "    # Show setup instructions for Colab users (only for professors)\n",
        "    if user_role == \"professor\":\n",
        "        setup_colab_tunnel()\n",
        "    \n",
        "    # Role-based interface\n",
        "    if user_role == \"professor\":\n",
        "        display_professor_interface(st.session_state.edu_system, auth_manager)\n",
        "        \n",
        "        # Show created quizzes for professor review\n",
        "        if 'available_quizzes' in st.session_state and st.session_state.available_quizzes:\n",
        "            st.markdown(\"---\")\n",
        "            st.markdown(\"### 📊 Your Created Quizzes\")\n",
        "            \n",
        "            for idx, quiz_info in enumerate(st.session_state.available_quizzes):\n",
        "                quiz = quiz_info['quiz']\n",
        "                with st.expander(f\"📝 {quiz.topic} ({quiz.difficulty_level.value.title()})\", expanded=False):\n",
        "                    col1, col2 = st.columns([3, 1])\n",
        "                    \n",
        "                    with col1:\n",
        "                        st.markdown(f\"\"\"\n",
        "                        **Quiz Details:**\n",
        "                        - **Questions**: {quiz.total_questions}\n",
        "                        - **Difficulty**: {quiz.difficulty_level.value.title()}\n",
        "                        - **Created**: {quiz.created_at.strftime('%Y-%m-%d %H:%M')}\n",
        "                        - **Source**: {quiz_info['file_name']}\n",
        "                        - **Cost**: ${quiz_info['metrics']['total_cost']:.4f}\n",
        "                        \"\"\")\n",
        "                    \n",
        "                    with col2:\n",
        "                        if st.button(f\"🔍 Preview Quiz\", key=f\"preview_{idx}\"):\n",
        "                            st.session_state.current_quiz = quiz\n",
        "                            st.session_state.quiz_mode = \"preview\"\n",
        "                            st.rerun()\n",
        "                        \n",
        "                        if st.button(f\"🗑️ Delete\", key=f\"delete_{idx}\", type=\"secondary\"):\n",
        "                            st.session_state.available_quizzes.pop(idx)\n",
        "                            st.rerun()\n",
        "            \n",
        "            # Show preview if professor is reviewing\n",
        "            if st.session_state.get('quiz_mode') == 'preview' and 'current_quiz' in st.session_state:\n",
        "                st.markdown(\"---\")\n",
        "                st.markdown(\"### 🔍 Quiz Preview\")\n",
        "                if st.button(\"⬅️ Back to Dashboard\"):\n",
        "                    st.session_state.quiz_mode = \"dashboard\"\n",
        "                    st.session_state.pop('current_quiz', None)\n",
        "                    st.rerun()\n",
        "                display_quiz(st.session_state.current_quiz)\n",
        "    \n",
        "    else:  # Student role\n",
        "        display_student_interface(auth_manager)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Ngrok Tunneling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "import os\n",
        "\n",
        "print(\"🎓 AI Quiz Generator - Colab Setup\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Get ngrok token\n",
        "try:\n",
        "    ngrok_token = userdata.get('NGROK_TOKEN')\n",
        "    if not ngrok_token:\n",
        "        print(\"❌ Ngrok token not found in Colab secrets\")\n",
        "        print(\"Add 'NGROK_TOKEN' to your Colab secrets to enable public access\")\n",
        "        print(\"Get token from: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "    else:\n",
        "        print(\"✅ Ngrok token retrieved!\")\n",
        "        ngrok.set_auth_token(ngrok_token)\n",
        "except Exception as e:\n",
        "    print(f\"❌ Ngrok setup failed: {e}\")\n",
        "\n",
        "# Function to run Streamlit\n",
        "def run_streamlit():\n",
        "    os.system(\"streamlit run education_system.py --server.port 8501 --server.enableCORS false --server.enableXsrfProtection false\")\n",
        "\n",
        "# Start Streamlit in background\n",
        "thread = threading.Thread(target=run_streamlit)\n",
        "thread.daemon = True\n",
        "thread.start()\n",
        "\n",
        "# Wait for it to start\n",
        "print(\"⏳ Starting Streamlit...\")\n",
        "time.sleep(10)\n",
        "\n",
        "# Create public URL\n",
        "try:\n",
        "    if 'ngrok_token' in locals() and ngrok_token:\n",
        "        print(\"🌐 Creating public tunnel...\")\n",
        "        public_url = ngrok.connect(8501)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"🎉 SUCCESS! Your AI Quiz Generator is now live!\")\n",
        "        print(\"=\"*60)\n",
        "        print(f\"🔗 Public URL: {public_url}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        print(\"\\n📋 Share this URL with your students!\")\n",
        "        print(\"⚠️  Keep this cell running to maintain the connection!\")\n",
        "    else:\n",
        "        print(\"⚠️  Running without public URL (ngrok token missing)\")\n",
        "        print(\"🔗 Local access: http://localhost:8501\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Tunnel creation failed: {e}\")\n",
        "    print(\"🔗 Try accessing locally: http://localhost:8501\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
